# -*- coding: utf-8 -*-
"""DSCI517.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FU9qS90pe0hVdSFhdGQ3rClMP7S2h_D8
"""

import statsmodels.api as sm
import pandas as pd
from google.colab import drive
import numpy as np

from statsmodels.stats.weightstats import ttest_ind
import statsmodels.formula.api as smf
from statsmodels.stats.power import FTestPower

drive.mount("/content/MyDrive")

"""## Data Load"""

df = pd.read_csv('./MyDrive/MyDrive/517/Response.csv')

df.columns

col_names = ['Timestamp','Migration', 'Start_Date','Age', 'Gender', 'Fluency', 'Difficulty', 'CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'RSI1', 'RSI2', 'RSI3', 'TSI1', 'TSI2', 'TSI3', 'SB1', 'SB2', 'SB3',  'SB4', 'SB5', 'SB6', 'SB7', 'SB8']
df.columns = col_names

df = df.drop(columns=['Timestamp', 'Start_Date', 'Difficulty'])

print(df.isna().values.sum())

df['Migration'] = df['Migration'].apply(
    lambda x: 1 if 'Fully Migrated' in x else 0
)

mapping_age = {'Under 18': 0, '18 - 24': 1,
           '25 - 34': 2, '35 - 44': 3,
           '45 - 54': 4, '55 - 64': 5,
           '65 and over': 6}

df['Age'] = df['Age'].map(mapping_age)

mapping_fluency = {'0 = None': 0, '1 = Beginner': 1,
                   '2 = Intermediate': 2, '3 = Advanced': 3,
                   '4 = Fluent': 4}

df['Fluency'] = df['Fluency'].map(mapping_fluency)

##migration_categories = ['0', '1']
##age_categories = ['Under 18', '18 - 24', '25 - 34', '35 - 44', '45 - 54', '55 - 64', '65 and over']
gender_categories = ['Male', 'Female']
##fluency_categories = ['0 = None', '1 = Beginner', '2 = Intermediate', '3 = Advanced', '4 = Fluent']

##df['Migration'] = pd.Categorical(df['Migration'], categories = migration_categories, ordered= True)
##df['Age'] = pd.Categorical(df['Age'], categories = age_categories, ordered= True)
df['Gender'] = pd.Categorical(df['Gender'], categories = gender_categories, ordered= False)
##df['Fluency'] = pd.Categorical(df['Fluency'], categories = fluency_categories, ordered= True)

df.head(3)

"""Reverse-scored

Acculturation
4.4, 4.5, 4.6 == ['TSI1', 'TSI2', 'TSI3']

Social Belonging
5.2, 5.3, 5.8 == ['SB2', 'SB3', 'SB8']
"""

df.columns

df['TSI1'] = 8 - df['TSI1']
df['TSI2'] = 8 - df['TSI2']
df['TSI3'] = 8 - df['TSI3']
df['SB2'] = 8 - df['SB2']
df['SB3'] = 8 - df['SB3']
df['SB8'] = 8 - df['SB8']

df['CultureShock'] = df[ ['CS1', 'CS2', 'CS3', 'CS4', 'CS5'] ].mean(axis=1)
df['Acculturation'] = df[ ['RSI1', 'RSI2', 'RSI3', 'TSI1', 'TSI2', 'TSI3'] ].mean(axis=1)
df['SocialBelonging'] = df[ ['SB1', 'SB2', 'SB3', 'SB4', 'SB5', 'SB6', 'SB7', 'SB8'] ].mean(axis=1)

df1 = df[['Migration','SocialBelonging','CultureShock', 'Acculturation', 'Age', 'Gender', 'Fluency']]

print(df1['Age'].unique())
print(df1['Gender'].unique())
print(df1['Fluency'].unique())

##df1['Age'] = pd.Categorical(df1['Age'], categories = ['18 - 24', '25 - 34', '35 - 44'], ordered = True)

df1.dtypes

"""Independent T-Test"""

from scipy.stats import levene

groupPartial = df1[df1['Migration'] == 0]['SocialBelonging']
groupFully = df1[df1['Migration'] == 1]['SocialBelonging']

stat, p_value = levene(groupFully, groupPartial)

print("Levene’s test p-value:", p_value)

# Perform t-test
t_stat, p_val, df = ttest_ind(groupFully, groupPartial, usevar='pooled')

# Calculate Cohen's d

g1 = groupFully.values
g2 = groupPartial.values

n1, n2 = len(g1), len(g2)
m1, m2 = np.mean(g1), np.mean(g2)
s1, s2 = np.std(g1, ddof=1), np.std(g2, ddof=1)

pooled_sd = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2))

# Cohen’s d
cohen_d = (m1 - m2) / pooled_sd


print(f"\nIndependent t-test Results:")
print("t-statistic:", t_stat)
print("p-value:", p_val)
print("degrees of freedom:", df)

print(f"Cohen’s d: {cohen_d:.3f}")

print(f"mean social belonging of Partial group: {m2}, sd: {s2}")
print(f"mean social belonging of Fully group: {m1}, sd: {s1}")

print(f"pooled_sd: {pooled_sd}")

print(f'GroupPartial #: {n2} \ngroupFully #:{n1}')

"""X + C -> Y"""

model1 = smf.ols('SocialBelonging ~ Migration + Age + Gender + Fluency', data = df1).fit()
print(model1.summary())

"""Power Analysis"""

model_wo_X = smf.ols('SocialBelonging ~ Age + Gender + Fluency', data = df1).fit()
print(model_wo_X.summary())

# Inputs
effect_size = 0.00305  # Ensure it's a scalar
alpha = 0.05
power = 0.80
df_num = 1

# Power analysis
analysis = FTestPower()
required_n = analysis.solve_power(effect_size=effect_size,
                                  df_num=df_num,
                                  alpha=alpha,
                                  power=power)

print(f"Required sample size: {required_n.item():.2f}")

"""X + C -> M"""

model2 = smf.ols('CultureShock ~ Migration + Age + Gender + Fluency', data = df1).fit()
print(model2.summary())

"""X + M + C -> Y"""

model3 = smf.ols('SocialBelonging ~ Migration + CultureShock + Age + Gender + Fluency', data = df1).fit()
print(model3.summary())

a = model2.params['Migration']
b = model3.params['CultureShock']
c_prime = model3.params['Migration']
c = model1.params['Migration']

indirect_effect = a*b
direct_effect = c_prime
total_effect = c
proportion_mediated = indirect_effect / total_effect if total_effect != 0 else None

print(f"Indirect Effect (a*b)      : {indirect_effect:.4f}")
print(f"Direct Effect (c')         : {direct_effect:.4f}")
print(f"Total Effect (c)           : {total_effect:.4f}")
print(f"Proportion Mediated (ab/c) : {proportion_mediated:.4f}" if proportion_mediated is not None else "Proportion Mediated: undefined (c=0)")

n_bootstraps = 5000

indirect_effects = []

for i in range(n_bootstraps):
    ## sampling without replacement
    sample_df = df1.sample(n=len(df1), replace=True)

    model_a_boot = smf.ols('CultureShock ~ Migration + Age + Gender + Fluency', data=sample_df).fit()
    model_b_boot = smf.ols('SocialBelonging ~ Migration + CultureShock + Age + Gender + Fluency', data=sample_df).fit()

    a_boot = model_a_boot.params.get('Migration', np.nan)
    b_boot = model_b_boot.params.get('CultureShock', np.nan)

    indirect_effects.append(a_boot * b_boot)

indirect_effects = np.array(indirect_effects)

## CI interval

lower_bound = np.percentile(indirect_effects, 2.5)
upper_bound = np.percentile(indirect_effects, 97.5)

print(f"Bootstrap 95% CI for indirect effect (a*b): ({lower_bound:.4f}, {upper_bound:.4f})")

if lower_bound > 0 or upper_bound < 0:
    print("Significant")
else:
    print("Not Significant.")

"""Simple regression for culture shock -> social belonging"""

model_CS_simple = smf.ols('SocialBelonging ~ CultureShock', data = df1).fit()
print(model_CS_simple.summary())

"""### acculturation"""

model_c = smf.ols('SocialBelonging ~ Migration + Age + Gender + Fluency', data = df1).fit()
print(model_c.summary())

model_a = smf.ols('Acculturation ~ Migration + Age + Gender + Fluency', data = df1).fit()
print(model_a.summary())

model_b = smf.ols('SocialBelonging ~ Migration + Acculturation + Age + Gender + Fluency', data = df1).fit()
print(model_b.summary())

df1.dtypes

n_bootstraps = 5000
indirect_effects = []

for _ in range(n_bootstraps):
    # sampling
    sample = df1.sample(n=len(df1), replace=True)

    # a: Migration + C → Acculturation ## X -> M
    model_a_bs = smf.ols('Acculturation ~ Migration + Age + Gender + Fluency', data=sample).fit()
    a_bs = model_a_bs.params.get('Migration', model_a_bs.params.get('Migration'))

    # b: Acculturation + Migration + C → SocialBelonging
        ## X + M + C -> Y
    model_b_bs = smf.ols('SocialBelonging ~ Migration + Acculturation + Age + Gender + Fluency', data=sample).fit()
    b_bs = model_b_bs.params.get('Acculturation')

    # 4.  a*b
    indirect_effects.append(a_bs * b_bs)


indirect_effects = np.array(indirect_effects)
lower_bound = np.percentile(indirect_effects, 2.5)
upper_bound = np.percentile(indirect_effects, 97.5)
mean_effect = np.mean(indirect_effects)


print(f"Bootstrap mean of a*b: {mean_effect:.4f}")
print(f"95% CI for indirect effect: ({lower_bound:.4f}, {upper_bound:.4f})")


if lower_bound > 0 or upper_bound < 0:
    print("Significant.")
else:
    print("Not Significant.")

print(df1['Migration'].value_counts())
print(df1['Migration'].value_counts(normalize=True))

